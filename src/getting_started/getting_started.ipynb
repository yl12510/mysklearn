{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "to practise main features of `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fitting and predicting: estimator basics\n",
    "\n",
    "estimators: built-in machine learning algorithms and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# simple example of using RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "X = [[1, 2, 3], [11, 12, 13]]  # sample matrix (n_samples, n_features)\n",
    "y = [0, 1]  # target values\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# using the fitted estimator to predict target values of training data\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# predict target values of new data\n",
    "clf.predict(\n",
    "    [\n",
    "        [\n",
    "            4,\n",
    "            5,\n",
    "            6,\n",
    "        ],\n",
    "        [14, 15, 16],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transformers and pre-processors\n",
    "\n",
    "A typical machine learning pipeline:\n",
    "1. preprocessing: transforms or imputes the data\n",
    "2. predicting: predicts the targeted value\n",
    "\n",
    "pre-processors, transformers, estimators all inherit from the `BaseEstimator` class\n",
    "- pre-processors & transformers don't have a predict method, but have a transform method\n",
    "- for certain use-cases, `ColumnTransformer` is designed for applying different transformations to different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# An example of using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = [[0, 15], [1, -10]]\n",
    "StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evaluation\n",
    "- sklearn provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "\n",
    "result = cross_validate(lr, X, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitting and predicting: estimator basics\n",
    "\n",
    "estimators: built-in machine learning algorithms and models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# simple example of using RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "X = [[1, 2, 3], [11, 12, 13]]  # sample matrix (n_samples, n_features)\n",
    "y = [0, 1]  # target values\n",
    "clf.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# using the fitted estimator to predict target values of training data\n",
    "clf.predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predict target values of new data\n",
    "clf.predict(\n",
    "    [\n",
    "        [\n",
    "            4,\n",
    "            5,\n",
    "            6,\n",
    "        ],\n",
    "        [14, 15, 16],\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformers and pre-processors\n",
    "\n",
    "A typical machine learning pipeline:\n",
    "1. preprocessing: transforms or imputes the data\n",
    "2. predicting: predicts the targeted value\n",
    "\n",
    "pre-processors, transformers, estimators all inherit from the `BaseEstimator` class\n",
    "- pre-processors & transformers don't have a predict method, but have a transform method\n",
    "- for certain use-cases, `ColumnTransformer` is designed for applying different transformations to different features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# An example of using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = [[0, 15], [1, -10]]\n",
    "StandardScaler().fit(X).transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "\n",
    "result = cross_validate(lr, X, y)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitting and predicting: estimator basics\n",
    "\n",
    "estimators: built-in machine learning algorithms and models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# simple example of using RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "X = [[1, 2, 3], [11, 12, 13]]  # sample matrix (n_samples, n_features)\n",
    "y = [0, 1]  # target values\n",
    "clf.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# using the fitted estimator to predict target values of training data\n",
    "clf.predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predict target values of new data\n",
    "clf.predict(\n",
    "    [\n",
    "        [\n",
    "            4,\n",
    "            5,\n",
    "            6,\n",
    "        ],\n",
    "        [14, 15, 16],\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformers and pre-processors\n",
    "\n",
    "A typical machine learning pipeline:\n",
    "1. preprocessing: transforms or imputes the data\n",
    "2. predicting: predicts the targeted value\n",
    "\n",
    "pre-processors, transformers, estimators all inherit from the `BaseEstimator` class\n",
    "- pre-processors & transformers don't have a predict method, but have a transform method\n",
    "- for certain use-cases, `ColumnTransformer` is designed for applying different transformations to different features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# An example of using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = [[0, 15], [1, -10]]\n",
    "StandardScaler().fit(X).transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "\n",
    "result = cross_validate(lr, X, y)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fitting and predicting: estimator basics\n",
    "\n",
    "estimators: built-in machine learning algorithms and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple example of using RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "X = [[1, 2, 3], [11, 12, 13]]  # sample matrix (n_samples, n_features)\n",
    "y = [0, 1]  # target values\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the fitted estimator to predict target values of training data\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict target values of new data\n",
    "clf.predict(\n",
    "    [\n",
    "        [\n",
    "            4,\n",
    "            5,\n",
    "            6,\n",
    "        ],\n",
    "        [14, 15, 16],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transformers and pre-processors\n",
    "\n",
    "A typical machine learning pipeline:\n",
    "1. preprocessing: transforms or imputes the data\n",
    "2. predicting: predicts the targeted value\n",
    "\n",
    "pre-processors, transformers, estimators all inherit from the `BaseEstimator` class\n",
    "- pre-processors & transformers don't have a predict method, but have a transform method\n",
    "- for certain use-cases, `ColumnTransformer` is designed for applying different transformations to different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# An example of using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = [[0, 15], [1, -10]]\n",
    "StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pipelines: chaining pre-processors and estimators\n",
    "- a pipeline offers the same API functions e.g. `fit` and `predict` as a regular estimator\n",
    "- using a pipeline can prevent from disclosing testing data in training data (i.e. data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96727e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# load the iris dataset and split into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# use it to predict over test data set and calculate accuracy score\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model evalutation\n",
    "\n",
    "A model needs to be evaluated to see if it can predict well over unseen data. \n",
    "- Cross validation is a particular tool for model evalation \n",
    "- sklean provides a `cross_validate` helper, which by default will perform a 5-fold cross validation\n",
    "- it is also possible to do manual iteration over folds, use different data splitting strategies, and use custom scoring functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02423596, 0.02805591, 0.02402782, 0.0249002 , 0.02508903]),\n",
       " 'score_time': array([0.00064802, 0.00030494, 0.0005331 , 0.00036502, 0.0002718 ]),\n",
       " 'test_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "\n",
    "result = cross_validate(lr, X, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
